{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86f0f4a5",
   "metadata": {},
   "source": [
    "# Assignment 04 - Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a470a6",
   "metadata": {},
   "source": [
    "## Part 1: Naive Bayes Classifier from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d142f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import string \n",
    "from string import digits\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b75f8c6",
   "metadata": {},
   "source": [
    "### Loading Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93e3a7d",
   "metadata": {},
   "source": [
    "#### Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "608798d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001</td>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002</td>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003</td>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>9998</td>\n",
       "      <td>Towards the end of the movie, I felt it was to...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>9999</td>\n",
       "      <td>This is the kind of movie that my enemies cont...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>999</td>\n",
       "      <td>I saw 'Descent' last night at the Stockholm Fi...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>99</td>\n",
       "      <td>Some films that you pick up for a pound turn o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>9</td>\n",
       "      <td>This is one of the dumbest films, I've ever se...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id                                            Reviews  Ratings  \\\n",
       "0          0  Bromwell High is a cartoon comedy. It ran at t...        9   \n",
       "1      10000  Homelessness (or Houselessness as George Carli...        8   \n",
       "2      10001  Brilliant over-acting by Lesley Ann Warren. Be...       10   \n",
       "3      10002  This is easily the most underrated film inn th...        7   \n",
       "4      10003  This is not the typical Mel Brooks film. It wa...        8   \n",
       "...      ...                                                ...      ...   \n",
       "24995   9998  Towards the end of the movie, I felt it was to...        4   \n",
       "24996   9999  This is the kind of movie that my enemies cont...        3   \n",
       "24997    999  I saw 'Descent' last night at the Stockholm Fi...        3   \n",
       "24998     99  Some films that you pick up for a pound turn o...        1   \n",
       "24999      9  This is one of the dumbest films, I've ever se...        1   \n",
       "\n",
       "       Sentiments  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               1  \n",
       "...           ...  \n",
       "24995           0  \n",
       "24996           0  \n",
       "24997           0  \n",
       "24998           0  \n",
       "24999           0  \n",
       "\n",
       "[25000 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positive sentinments in train \n",
    "sentiments_train=[]\n",
    "for name in glob.glob('../IMDB_Dataset/Dataset/train/pos/*'):\n",
    "    with open(name, encoding=\"utf8\") as fn:\n",
    "        content = fn.readlines()\n",
    "        sentiments_train.append([int(name.split(\"\\\\\")[1].split(\"_\")[0]),content[0],int(name.split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]),1])\n",
    "\n",
    "# negative sentiments in train\n",
    "for name in glob.glob('../IMDB_Dataset/Dataset/train/neg//*'):\n",
    "    with open(name, encoding=\"utf8\") as fn:\n",
    "        content = fn.readlines()\n",
    "        sentiments_train.append([int(name.split(\"\\\\\")[1].split(\"_\")[0]),content[0],int(name.split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]),0])\n",
    "    \n",
    "# Create the pandas DataFrame\n",
    "df_train = pd.DataFrame(sentiments_train, columns = ['Id', 'Reviews','Ratings','Sentiments'])\n",
    " \n",
    "# print dataframe.\n",
    "df_train\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b37c75",
   "metadata": {},
   "source": [
    "#### Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16559061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001</td>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002</td>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003</td>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>9998</td>\n",
       "      <td>I occasionally let my kids watch this garbage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>9999</td>\n",
       "      <td>When all we have anymore is pretty much realit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>999</td>\n",
       "      <td>The basic genre is a thriller intercut with an...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>99</td>\n",
       "      <td>Four things intrigued me as to this film - fir...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>9</td>\n",
       "      <td>David Bryce's comments nearby are exceptionall...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id                                            Reviews  Ratings  \\\n",
       "0          0  I went and saw this movie last night after bei...       10   \n",
       "1      10000  Actor turned director Bill Paxton follows up h...        7   \n",
       "2      10001  As a recreational golfer with some knowledge o...        9   \n",
       "3      10002  I saw this film in a sneak preview, and it is ...        8   \n",
       "4      10003  Bill Paxton has taken the true story of the 19...        8   \n",
       "...      ...                                                ...      ...   \n",
       "24995   9998  I occasionally let my kids watch this garbage ...        1   \n",
       "24996   9999  When all we have anymore is pretty much realit...        1   \n",
       "24997    999  The basic genre is a thriller intercut with an...        3   \n",
       "24998     99  Four things intrigued me as to this film - fir...        3   \n",
       "24999      9  David Bryce's comments nearby are exceptionall...        4   \n",
       "\n",
       "       Sentiments  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               1  \n",
       "...           ...  \n",
       "24995           0  \n",
       "24996           0  \n",
       "24997           0  \n",
       "24998           0  \n",
       "24999           0  \n",
       "\n",
       "[25000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # positive sentinments in train \n",
    "sentiments_test=[]\n",
    "for name in glob.glob('../IMDB_Dataset/Dataset/test/pos/*'):\n",
    "    with open(name, encoding=\"utf8\") as fn:\n",
    "        content = fn.readlines()\n",
    "        sentiments_test.append([int(name.split(\"\\\\\")[1].split(\"_\")[0]),content[0],int(name.split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]),1])\n",
    "\n",
    "# negative sentiments in train\n",
    "for name in glob.glob('../IMDB_Dataset/Dataset/test/neg//*'):\n",
    "    with open(name, encoding=\"utf8\") as fn:\n",
    "        content = fn.readlines()\n",
    "        sentiments_test.append([int(name.split(\"\\\\\")[1].split(\"_\")[0]),content[0],int(name.split(\"\\\\\")[1].split(\"_\")[1].split(\".\")[0]),0])\n",
    "       \n",
    "    \n",
    "# Create the pandas DataFrame\n",
    "df_test= pd.DataFrame(sentiments_test, columns = ['Id', 'Reviews','Ratings','Sentiments'])\n",
    " \n",
    "# print dataframe.\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec308038",
   "metadata": {},
   "source": [
    "### Pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544d091a",
   "metadata": {},
   "source": [
    "#### Removing stop words and cleaning data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52314a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>went saw movie last night coaxed friends mine ...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>actor turned director bill paxton follows prom...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001</td>\n",
       "      <td>recreational golfer knowledge sports history p...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002</td>\n",
       "      <td>saw film sneak preview delightful cinematograp...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003</td>\n",
       "      <td>bill paxton taken true story  us golf open mad...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>9998</td>\n",
       "      <td>occasionally let kids watch garbage understand...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>9999</td>\n",
       "      <td>anymore pretty much reality tv shows people ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>999</td>\n",
       "      <td>basic genre thriller intercut uncomfortable me...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>99</td>\n",
       "      <td>four things intrigued film  firstly stars carl...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>9</td>\n",
       "      <td>david bryces comments nearby exceptionally wel...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id                                            Reviews  Ratings  \\\n",
       "0          0  went saw movie last night coaxed friends mine ...       10   \n",
       "1      10000  actor turned director bill paxton follows prom...        7   \n",
       "2      10001  recreational golfer knowledge sports history p...        9   \n",
       "3      10002  saw film sneak preview delightful cinematograp...        8   \n",
       "4      10003  bill paxton taken true story  us golf open mad...        8   \n",
       "...      ...                                                ...      ...   \n",
       "24995   9998  occasionally let kids watch garbage understand...        1   \n",
       "24996   9999  anymore pretty much reality tv shows people ma...        1   \n",
       "24997    999  basic genre thriller intercut uncomfortable me...        3   \n",
       "24998     99  four things intrigued film  firstly stars carl...        3   \n",
       "24999      9  david bryces comments nearby exceptionally wel...        4   \n",
       "\n",
       "       Sentiments  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               1  \n",
       "...           ...  \n",
       "24995           0  \n",
       "24996           0  \n",
       "24997           0  \n",
       "24998           0  \n",
       "24999           0  \n",
       "\n",
       "[25000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading stop_words into file \n",
    "f = open(\"../IMDB_Dataset/Dataset/stop_words.txt\", \"r\")\n",
    "stop_words=f.read().splitlines()\n",
    "\n",
    "def cleaning(review):\n",
    "    review = review.replace(\"<br>\", \"\").replace(\"</br>\", \"\")\n",
    "    review=review.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokenized_review = review.split(' ')\n",
    "    review_wsw = [word for word in tokenized_review if not word in stop_words]\n",
    "    review = (\" \").join(review_wsw)\n",
    "    review=re.sub('[^A-Za-z0-9 ]+', '', review)\n",
    "    \n",
    "    \n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    review= review.translate(remove_digits)\n",
    "    review = review.rstrip()\n",
    "    return review.lower()\n",
    "    \n",
    "    \n",
    "    \n",
    "df_train['Reviews'] = df_train['Reviews'].map(lambda review: cleaning(review)  )\n",
    "df_test['Reviews'] = df_test['Reviews'].map(lambda review: cleaning(review)  )\n",
    "\n",
    "\n",
    "\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8919a041",
   "metadata": {},
   "source": [
    "### Train Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "203dfe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNaiveBayes(data,classes):\n",
    "    bigdoc={}\n",
    "    logprior={}\n",
    "    N_doc=data.shape[0]\n",
    "    c=0\n",
    "    vocabulary=set()\n",
    "    totalnegv=[]\n",
    "    totalposv=[]\n",
    "    classCount=[]\n",
    "    negvocab=[]\n",
    "    posvocab=[]\n",
    "    p_dict={}\n",
    "    n_dict={}\n",
    "    \n",
    "    #creating functions to count the words in the positive and negative sentiments with all reps\n",
    "    def poscount(sentence):\n",
    "        [posvocab.append(word) for word in sentence if word!='']\n",
    "        \n",
    "    def negcount(sentence):\n",
    "        [negvocab.append(word) for word in sentence if word!='']\n",
    "    \n",
    "    # returnning correct count from either class\n",
    "    def count(word,class_word):\n",
    "        count=0\n",
    "        if class_word==1:\n",
    "            if word not in p_dict.keys():\n",
    "                count=0\n",
    "            else:\n",
    "                count=p_dict[word]\n",
    "        if class_word==0:\n",
    "            if word not in n_dict.keys():\n",
    "                count=0\n",
    "            else:\n",
    "                count=n_dict[word]\n",
    "            \n",
    "        return count\n",
    "    \n",
    "#   splitting the sentiment column to good and bad and calling function on each value\n",
    "    data.loc[data['Sentiments'] == 1]['Reviews'].map(lambda review: poscount(review.split(\" \")) )\n",
    "    data.loc[data['Sentiments'] == 0]['Reviews'].map(lambda review:negcount(review.split(\" \")) )\n",
    "\n",
    "\n",
    "#   allocating words from the list of all words with their counts \n",
    "    for word in negvocab:\n",
    "        if word not in n_dict:\n",
    "            n_dict[word] = 0 \n",
    "        n_dict[word] += 1\n",
    "        \n",
    "    for word in posvocab:\n",
    "        if word not in p_dict:\n",
    "            p_dict[word] = 0 \n",
    "        p_dict[word] += 1\n",
    "    totalCount=[len(p_dict),len( n_dict)]\n",
    "\n",
    "    \n",
    "    \n",
    "#   getting the entire vocabulary\n",
    "    data['Reviews'].map(lambda review: [vocabulary.add(word) for word in review.split(\" \") if word!=''])\n",
    "\n",
    "    \n",
    "    \n",
    "    for class_data in classes:    \n",
    "        \n",
    "        bigdoc[class_data] = data.loc[data['Sentiments'] == class_data]\n",
    "        N_c=len(bigdoc[class_data])\n",
    "        logprior[class_data]=np.log(N_c/ N_doc)\n",
    "        loglikelihood[class_data] = {}\n",
    "\n",
    "        for word in vocabulary:\n",
    "            c=count(word,class_data)\n",
    "            loglikelihood[class_data][word]=np.log( (c+1)/(len(vocabulary)+totalCount[class_data] ))\n",
    "        \n",
    "    \n",
    "    return logprior, loglikelihood, vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500b4c6b",
   "metadata": {},
   "source": [
    "#### Calling the function and getting parameters for train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ba930197",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=df_train.copy()\n",
    "classes=data[data.iloc[:,-1:].columns[0]].unique()\n",
    "\n",
    "logprior, loglikelihood, vocabulary=trainNaiveBayes(data,classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c72ec8",
   "metadata": {},
   "source": [
    "### Test Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b7b390ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testNaiveBayes(testdoc, logprior, loglikelihood, C, V):\n",
    "    sum_class = {}\n",
    "    testdoc= testdoc.split(\" \")\n",
    "    for class_word in classes:\n",
    "        sum_class[class_word] = logprior[class_word]\n",
    "        for word in testdoc:\n",
    "            if word in V:\n",
    "                sum_class[class_word] = sum_class[class_word] + loglikelihood[class_word][word]\n",
    "                \n",
    "    return max(sum_class, key=sum_class.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afb7f3e",
   "metadata": {},
   "source": [
    "#### Evaluation for the obtained labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4e690145",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "groundLabel=df_test['Sentiments'].to_list()\n",
    "predictedlabels=[]\n",
    "\n",
    "df_test['Reviews'].map(lambda review: predictedlabels.append(testNaiveBayes(review, logprior, loglikelihood, [0, 1], vocabulary))  )\n",
    "\n",
    "for i in range(df_test.shape[0]):\n",
    "    if (groundLabel[i]== 1 and predictedlabels[i]==1 ):\n",
    "        tp = tp + 1\n",
    "    elif (groundLabel[i]== 0 and predictedlabels[i]==0 ):\n",
    "        tn = tn + 1\n",
    "    elif (groundLabel[i]== 0 and predictedlabels[i]==1 ):\n",
    "        fp = fp + 1\n",
    "    elif (groundLabel[i]== 1 and predictedlabels[i]==0 ):\n",
    "        fn = fn + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e7f245",
   "metadata": {},
   "source": [
    "### Confusion matrix and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "adb5da40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Confusion Matrix: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[10700,  2418],\n",
       "       [ 1800, 10082]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.128 %\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = np.array([ [tp, fp], [fn, tn] ])\n",
    "accuracy = (tn + tp) / (tn + tp + fn + fp)\n",
    "display(\"Confusion Matrix: \",confusion_matrix)\n",
    "print(\"Accuracy:\", accuracy*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c637759",
   "metadata": {},
   "source": [
    "## Part 2: Naive Bayes scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258d8e99",
   "metadata": {},
   "source": [
    "#### Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ac735594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77809156",
   "metadata": {},
   "source": [
    "#### Vectorizing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "005397ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "countVector = CountVectorizer(stop_words= stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c33ecb",
   "metadata": {},
   "source": [
    "#### Fit and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "695f2aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_matrix = countVector.fit_transform(df_train['Reviews'].values.flatten().tolist())\n",
    "df_test_matrix = countVector.transform(df_test['Reviews'].values.flatten().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f14698",
   "metadata": {},
   "source": [
    "#### Initiating Multi-Nomial Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4d94b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(df_train_matrix, df_train['Sentiments'].values.flatten().tolist())\n",
    "PredictedVals = nb.predict(df_test_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b794526",
   "metadata": {},
   "source": [
    "#### Stating Evaluation report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "75dcd37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[10993  1507]\n",
      " [ 2884  9616]]\n",
      "Accuracy:  82.43599999999999 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Confusion matrix: \\n\",metrics.confusion_matrix(df_test['Sentiments'].to_list(), PredictedVals))\n",
    "print(\"Accuracy: \", metrics.accuracy_score(df_train['Sentiments'].to_list(), PredictedVals) * 100, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
